{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Level Strategies:\n",
    "1. Prompting\n",
    "2. Function calling\n",
    "3. Tool Calling\n",
    "4. Json Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='8.9 is greater than 8.11.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 20, 'total_tokens': 31}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_507c9469a1', 'finish_reason': 'stop', 'logprobs': None}, id='run-6fc3d229-f2b2-4d1c-9f14-48c0c96ce290-0', usage_metadata={'input_tokens': 20, 'output_tokens': 11, 'total_tokens': 31})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"which one is greater 8.11 or 8.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \t'''\n",
    "Alice: Hi, I bought a laptop from your store recently, but it's really slow and gets hot quickly. Can you help?\n",
    "John: Hi Alice, I'm sorry to hear that. I'm here to assist. Can you tell me the model and when you purchased it?\n",
    "Alice: It's the XYZ UltraBook 15, and I bought it two weeks ago.\n",
    "John: Thanks, Alice. The slowness could be due to background processes or memory issues. Does it happen with specific apps?\n",
    "Alice: Yes, mostly when I’m using video editing software or have many browser tabs open.\n",
    "John: That makes sense. Let’s check the Task Manager. Press Ctrl + Shift + Esc to see which processes are using a lot of resources.\n",
    "Alice: I see the video software and something called “svchost.exe” using a lot of memory.\n",
    "John: The video software is expected to use a lot, but svchost.exe might just need a restart to clear it up. How about the overheating?\n",
    "Alice: Yes, it gets really hot after a short time.\n",
    "John: Overheating can be due to blocked vents or high CPU usage. Try cleaning the vents and placing the laptop on a hard surface. If it continues, check for updates or bring it in for a diagnostic.\n",
    "Alice: Okay, I'll try that. Thanks for your help, John.\n",
    "John: You’re welcome, Alice! Let me know if you need anything else. Have a great day!\n",
    "Alice: Thanks, you too!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''You are provided with a conversation between customer and agent. \n",
    "        Your task is to extract key information like Topic of conversation, name of customer and agent, sentiment of the call between 1 to 5.\n",
    "        Always provide results in json format nothing else.\n",
    "        Conversation: {conversation}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Topic\": \"Laptop performance issues\",\n",
      "  \"CustomerName\": \"Alice\",\n",
      "  \"AgentName\": \"John\",\n",
      "  \"Sentiment\": 4\n",
      "}\n",
      "```\n",
      "Tokens Used: 405\n",
      "\tPrompt Tokens: 366\n",
      "\tCompletion Tokens: 39\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    out = llm.invoke(prompt)\n",
    "print(out.content)\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Summarization(BaseModel):\n",
    "    \"\"\"Extract key information from the conversation.\"\"\"\n",
    "\n",
    "    Topic: str = Field(description=\"What was the topic of discussion in the call.\")\n",
    "    Customer: str = Field(description=\"Name of the customer\")\n",
    "    Agent: str = Field(description=\"Name of the Agent\")\n",
    "    Sentiment: int = Field(description=\"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Summarization'> \n",
      " Topic='Laptop performance issues' Customer='Alice' Agent='John' Sentiment=4\n",
      "Tokens Used: 440\n",
      "\tPrompt Tokens: 420\n",
      "\tCompletion Tokens: 20\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(Summarization)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    out = structured_llm.invoke(f\"{conversation}\")\n",
    "\n",
    "print(type(out), \"\\n\", out)\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Laptop performance issues'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
       " 'kwargs': {'first': RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001DB8EB99100>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001DB8EB9A5D0>, root_client=<openai.OpenAI object at 0x000001DB8E7954C0>, root_async_client=<openai.AsyncOpenAI object at 0x000001DB8EB99130>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Summarization', 'description': 'Extract key information from the conversation.', 'parameters': {'type': 'object', 'properties': {'Topic': {'description': 'What was the topic of discussion in the call.', 'type': 'string'}, 'Customer': {'description': 'Name of the customer', 'type': 'string'}, 'Agent': {'description': 'Name of the Agent', 'type': 'string'}, 'Sentiment': {'description': 'What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive', 'type': 'integer'}}, 'required': ['Topic', 'Customer', 'Agent', 'Sentiment']}}}], 'parallel_tool_calls': False, 'tool_choice': {'type': 'function', 'function': {'name': 'Summarization'}}}),\n",
       "  'last': PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Summarization'>])},\n",
       " 'name': 'RunnableSequence',\n",
       " 'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'ChatOpenAIInput'},\n",
       "   {'id': 1,\n",
       "    'type': 'runnable',\n",
       "    'data': {'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "     'name': 'ChatOpenAI'},\n",
       "    'metadata': {}},\n",
       "   {'id': 2,\n",
       "    'type': 'runnable',\n",
       "    'data': {'id': ['langchain_core',\n",
       "      'output_parsers',\n",
       "      'openai_tools',\n",
       "      'PydanticToolsParser'],\n",
       "     'name': 'PydanticToolsParser'}},\n",
       "   {'id': 3, 'type': 'schema', 'data': 'PydanticToolsParserOutput'}],\n",
       "  'edges': [{'source': 0, 'target': 1},\n",
       "   {'source': 2, 'target': 3},\n",
       "   {'source': 1, 'target': 2}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> \n",
      " {'Topic': 'Laptop performance issues', 'Customer': 'Alice', 'Agent': 'John', 'Sentiment': 2}\n",
      "Tokens Used: 392\n",
      "\tPrompt Tokens: 372\n",
      "\tCompletion Tokens: 20\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class Summarization(TypedDict):\n",
    "    \"\"\"Extract key information from the conversation.\"\"\"\n",
    "\n",
    "    Topic: str = Field(description=\"What was the topic of discussion in the call.\")\n",
    "    Customer: str = Field(description=\"Name of the customer\")\n",
    "    Agent: str = Field(description=\"Name of the Agent\")\n",
    "    Sentiment: int = Field(description=\"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Summarization)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    out = structured_llm.invoke(f\"{conversation}\")\n",
    "\n",
    "print(type(out), \"\\n\", out)\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class ConversationalResponse(BaseModel):\n",
    "    \"\"\"Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
    "\n",
    "    response: str = Field(description=\"A conversational response to the user's query\")\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    output: Union[Summarization, ConversationalResponse]\n",
    "\n",
    "structured_llm = llm.with_structured_output(Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Response'> \n",
      " output=ConversationalResponse(response='The current President of India is Droupadi Murmu. She took office on July 25, 2022, and is the first tribal woman to hold the position.')\n",
      "Tokens Used: 158\n",
      "\tPrompt Tokens: 117\n",
      "\tCompletion Tokens: 41\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    out = structured_llm.invoke(\"Who is president of India?\")\n",
    "\n",
    "print(type(out), \"\\n\", out)\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Response'> \n",
      " output={'Topic': 'Laptop Performance Issues', 'Customer': 'Alice', 'Agent': 'John', 'Sentiment': 4}\n",
      "Tokens Used: 437\n",
      "\tPrompt Tokens: 415\n",
      "\tCompletion Tokens: 22\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    out = structured_llm.invoke(f\"{conversation}\")\n",
    "\n",
    "print(type(out), \"\\n\", out)\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarization(BaseModel):\n",
    "    \"\"\"Extract key information from the conversation.\"\"\"\n",
    "\n",
    "    Topic: str = Field(description=\"What was the topic of discussion in the call.\")\n",
    "    Customer: str = Field(description=\"Name of the customer\")\n",
    "    Agent: str = Field(description=\"Name of the Agent\")\n",
    "    Sentiment: int = Field(description=\"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\")\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Extract key information from the conversation.\", \"properties\": {\"Topic\": {\"title\": \"Topic\", \"description\": \"What was the topic of discussion in the call.\", \"type\": \"string\"}, \"Customer\": {\"title\": \"Customer\", \"description\": \"Name of the customer\", \"type\": \"string\"}, \"Agent\": {\"title\": \"Agent\", \"description\": \"Name of the Agent\", \"type\": \"string\"}, \"Sentiment\": {\"title\": \"Sentiment\", \"description\": \"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\", \"type\": \"integer\"}}, \"required\": [\"Topic\", \"Customer\", \"Agent\", \"Sentiment\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Extract key information from the conversation.\", \"properties\": {\"Topic\": {\"title\": \"Topic\", \"description\": \"What was the topic of discussion in the call.\", \"type\": \"string\"}, \"Customer\": {\"title\": \"Customer\", \"description\": \"Name of the customer\", \"type\": \"string\"}, \"Agent\": {\"title\": \"Agent\", \"description\": \"Name of the Agent\", \"type\": \"string\"}, \"Sentiment\": {\"title\": \"Sentiment\", \"description\": \"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\", \"type\": \"integer\"}}, \"required\": [\"Topic\", \"Customer\", \"Agent\", \"Sentiment\"]}\\n```'} template='Answer the user query.\\n{format_instructions}\\n{query}\\n'\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Topic': 'Laptop performance issues', 'Customer': 'Alice', 'Agent': 'John', 'Sentiment': 3}\n",
      "Tokens Used: 628\n",
      "\tPrompt Tokens: 591\n",
      "\tCompletion Tokens: 37\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    out = chain.invoke(f\"{conversation}\")\n",
    "\n",
    "print(out)\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Topic\": \"Laptop performance issues\", \"Customer\": \"Alice\", \"Agent\": \"John\", \"Sentiment\": 3}'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
